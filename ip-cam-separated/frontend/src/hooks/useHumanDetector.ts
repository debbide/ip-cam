import { useRef, useState, useEffect, useCallback } from 'react';
import { toast } from 'sonner';
import * as cocoSsd from '@tensorflow-models/coco-ssd';
import '@tensorflow/tfjs';
import { addEventToStorage, MotionEvent } from '@/components/MotionEventLog';
import { DetectionRegion } from '@/types/camera';

interface HumanDetectorOptions {
    checkInterval?: number; // Milliseconds between checks
    cooldownTime?: number; // Milliseconds between alerts
    confidenceThreshold?: number; // Minimum confidence to trigger (0-1)
    onHumanDetected?: (event: MotionEvent) => void;
    persistent?: boolean; // æŒä¹…æ¨¡å¼ï¼šç»„ä»¶å¸è½½åç»§ç»­æ£€æµ‹
    detectionRegion?: DetectionRegion; // æ£€æµ‹åŒºåŸŸ
}

interface HumanDetectorResult {
    isDetecting: boolean;
    humanDetected: boolean;
    detectionCount: number;
    isModelLoading: boolean;
    startDetection: () => void;
    stopDetection: () => void;
    toggleDetection: () => void;
}

// å…¨å±€å­˜å‚¨ï¼šæ£€æµ‹ interval å’ŒçŠ¶æ€ï¼ˆä¸éšç»„ä»¶å¸è½½è€Œé”€æ¯ï¼‰
const globalIntervals = new Map<string, number>();
const globalDetectionStates = new Map<string, { humanDetected: boolean; detectionCount: number }>();
let globalModel: cocoSsd.ObjectDetection | null = null;
let globalModelLoading = false;

// åŠ è½½å…¨å±€æ¨¡å‹
async function loadGlobalModel(): Promise<cocoSsd.ObjectDetection | null> {
    if (globalModel) return globalModel;
    if (globalModelLoading) {
        // ç­‰å¾…åŠ è½½å®Œæˆ
        while (globalModelLoading) {
            await new Promise(r => setTimeout(r, 100));
        }
        return globalModel;
    }

    globalModelLoading = true;
    try {
        console.log('[HumanDetector] Loading COCO-SSD model...');
        globalModel = await cocoSsd.load({
            base: 'lite_mobilenet_v2'
        });
        console.log('[HumanDetector] Model loaded successfully');
        return globalModel;
    } catch (error) {
        console.error('[HumanDetector] Failed to load model:', error);
        toast.error('AI æ¨¡å‹åŠ è½½å¤±è´¥');
        return null;
    } finally {
        globalModelLoading = false;
    }
}

export function useHumanDetector(
    videoRef: React.RefObject<HTMLVideoElement | null>,
    cameraName: string,
    cameraId: string = '',
    options: HumanDetectorOptions = {}
): HumanDetectorResult {
    const {
        checkInterval = 1000,
        cooldownTime = 10000,
        confidenceThreshold = 0.5,
        onHumanDetected,
        persistent = true, // é»˜è®¤å¼€å¯æŒä¹…æ¨¡å¼
        detectionRegion,
    } = options;

    const [isDetecting, setIsDetecting] = useState(() => globalIntervals.has(cameraId));
    const [humanDetected, setHumanDetected] = useState(() => globalDetectionStates.get(cameraId)?.humanDetected || false);
    const [detectionCount, setDetectionCount] = useState(() => globalDetectionStates.get(cameraId)?.detectionCount || 0);
    const [isModelLoading, setIsModelLoading] = useState(false);

    const lastAlertRef = useRef<number>(0);
    const detectionRegionRef = useRef(detectionRegion);

    // æ›´æ–° detectionRegionRef
    useEffect(() => {
        detectionRegionRef.current = detectionRegion;
    }, [detectionRegion]);

    // åŒæ­¥å…¨å±€çŠ¶æ€åˆ°æœ¬åœ°çŠ¶æ€
    useEffect(() => {
        const interval = setInterval(() => {
            const state = globalDetectionStates.get(cameraId);
            if (state) {
                setHumanDetected(state.humanDetected);
                setDetectionCount(state.detectionCount);
            }
            setIsDetecting(globalIntervals.has(cameraId));
        }, 500);
        return () => clearInterval(interval);
    }, [cameraId]);

    // æ£€æŸ¥æ£€æµ‹ç»“æœæ˜¯å¦åœ¨æŒ‡å®šåŒºåŸŸå†…
    const isInRegion = useCallback((
        bbox: [number, number, number, number], // [x, y, width, height]
        videoWidth: number,
        videoHeight: number,
        region?: DetectionRegion
    ): boolean => {
        if (!region) return true; // æ²¡æœ‰é™å®šåŒºåŸŸåˆ™å…¨ç”»é¢æ£€æµ‹

        // å°†æ£€æµ‹æ¡†åæ ‡è½¬æ¢ä¸ºç›¸å¯¹å€¼
        const [bx, by, bw, bh] = bbox;
        const relX = bx / videoWidth;
        const relY = by / videoHeight;
        const relW = bw / videoWidth;
        const relH = bh / videoHeight;

        // è®¡ç®—æ£€æµ‹æ¡†ä¸­å¿ƒç‚¹
        const centerX = relX + relW / 2;
        const centerY = relY + relH / 2;

        // æ£€æŸ¥ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨åŒºåŸŸå†…
        return (
            centerX >= region.x &&
            centerX <= region.x + region.width &&
            centerY >= region.y &&
            centerY <= region.y + region.height
        );
    }, []);

    const detectHumans = useCallback(async () => {
        const video = videoRef.current;
        const model = globalModel;

        if (!video || !model || video.readyState < 2 || video.videoWidth === 0) {
            return;
        }

        try {
            const predictions = await model.detect(video);
            const humans = predictions.filter(
                p => p.class === 'person' &&
                    p.score >= confidenceThreshold &&
                    isInRegion(p.bbox as [number, number, number, number], video.videoWidth, video.videoHeight, detectionRegionRef.current)
            );

            // æ›´æ–°å…¨å±€çŠ¶æ€
            globalDetectionStates.set(cameraId, {
                humanDetected: humans.length > 0,
                detectionCount: humans.length
            });

            if (humans.length > 0) {
                setHumanDetected(true);
                setDetectionCount(humans.length);

                const now = Date.now();
                if (now - lastAlertRef.current > cooldownTime) {
                    lastAlertRef.current = now;

                    const event: MotionEvent = {
                        id: `human-${now}-${Math.random().toString(36).substr(2, 9)}`,
                        cameraName,
                        cameraId,
                        timestamp: new Date(),
                        motionLevel: humans[0].score,
                    };

                    addEventToStorage(event);
                    onHumanDetected?.(event);

                    toast.warning(`äººå½¢ä¾¦æµ‹å‘Šè­¦`, {
                        description: `${cameraName} æ£€æµ‹åˆ° ${humans.length} äºº (ç½®ä¿¡åº¦: ${(humans[0].score * 100).toFixed(0)}%)`,
                        duration: 5000,
                    });

                    // è‡ªåŠ¨æŠ“æ‹
                    let imageBase64: string | undefined;
                    try {
                        const { saveScreenshot } = await import('@/utils/fileSaver');
                        await saveScreenshot(video, cameraName, 'äººå½¢æ£€æµ‹', 'äººå½¢æ£€æµ‹');

                        // è·å–æˆªå›¾ base64 ç”¨äº TG æ¨é€
                        const canvas = document.createElement('canvas');
                        canvas.width = video.videoWidth || 640;
                        canvas.height = video.videoHeight || 480;
                        const ctx = canvas.getContext('2d');
                        if (ctx) {
                            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                            const dataUrl = canvas.toDataURL('image/jpeg', 0.7);
                            imageBase64 = dataUrl.replace(/^data:image\/\w+;base64,/, '');
                        }
                    } catch (e) {
                        console.error('[HumanDetector] Auto-capture failed:', e);
                    }

                    // å‘é€ Telegram é€šçŸ¥
                    if (window.electronAPI?.sendNotification) {
                        try {
                            const message = `ğŸš¨ äººå½¢ä¾¦æµ‹å‘Šè­¦\nğŸ“· ${cameraName}\nğŸ• ${new Date().toLocaleString('zh-CN')}`;
                            await window.electronAPI.sendNotification(message, imageBase64);
                            console.log('[HumanDetector] TG notification sent');
                        } catch (notifyError) {
                            console.error('[HumanDetector] TG notification failed:', notifyError);
                        }
                    }
                }
            } else {
                setHumanDetected(false);
                setDetectionCount(0);
            }
        } catch (e) {
            console.debug('[HumanDetector] Detection error:', e);
        }
    }, [videoRef, cameraName, cameraId, confidenceThreshold, cooldownTime, onHumanDetected, isInRegion]);

    const startDetection = useCallback(async () => {
        if (globalIntervals.has(cameraId)) return;

        setIsModelLoading(true);
        const model = await loadGlobalModel();
        setIsModelLoading(false);

        if (!model) {
            toast.error('AI æ¨¡å‹æœªåŠ è½½');
            return;
        }

        setIsDetecting(true);

        // å­˜å‚¨åˆ°å…¨å±€ Map
        const intervalId = window.setInterval(detectHumans, checkInterval);
        globalIntervals.set(cameraId, intervalId);

        toast.success(`å·²å¼€å¯äººå½¢ä¾¦æµ‹`, { description: cameraName });
    }, [cameraId, cameraName, detectHumans, checkInterval]);

    const stopDetection = useCallback(() => {
        const intervalId = globalIntervals.get(cameraId);
        if (intervalId) {
            clearInterval(intervalId);
            globalIntervals.delete(cameraId);
        }
        globalDetectionStates.delete(cameraId);

        setIsDetecting(false);
        setHumanDetected(false);
        setDetectionCount(0);

        toast.info(`å·²å…³é—­äººå½¢ä¾¦æµ‹`, { description: cameraName });
    }, [cameraId, cameraName]);

    const toggleDetection = useCallback(() => {
        if (isDetecting) {
            stopDetection();
        } else {
            startDetection();
        }
    }, [isDetecting, startDetection, stopDetection]);

    // ç»„ä»¶å¸è½½æ—¶ï¼Œå¦‚æœä¸æ˜¯æŒä¹…æ¨¡å¼åˆ™åœæ­¢æ£€æµ‹
    useEffect(() => {
        return () => {
            if (!persistent) {
                stopDetection();
            }
        };
    }, [persistent, stopDetection]);

    return {
        isDetecting,
        humanDetected,
        detectionCount,
        isModelLoading,
        startDetection,
        stopDetection,
        toggleDetection,
    };
}
